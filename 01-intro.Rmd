---
title: "Introduction to Tidy Data"
author: "Alison Hill & Daniel Anderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
---

This is a lesson on tidying data, remixed from [Jenny Bryan's similar lesson using "Lord of the Rings" data](https://github.com/jennybc/lotr-tidy). Most text + code is Jenny's, basically we plopped a new dataset in there `r emo::ji("wink")`

---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE, collapse = TRUE, comment = "#>", warning = FALSE, message = FALSE)
library(tidyverse)
library(DT)
```

```{r prepare-tidy-data, include = FALSE}
if (!file.exists(here::here("data", "tidy-gbbo-bakes.csv"))) {
  download.file(paste0("https://raw.githubusercontent.com/apreshill/",
                       "bakeoff/master/tidy-gbbo-bakes.csv"), 
                destfile = here::here("data", "tidy-gbbo-bakes.csv"),
                method = "curl")
}

bakes_tidy <- read_csv(here::here("data", "tidy-gbbo-bakes.csv"),
                       col_types = cols(series = col_factor(levels = NULL))) %>% 
  count(series, challenge, cake) %>% 
  drop_na(cake) %>% 
  rename(bakes = n)

#write_csv(bakes_tidy, here::here("data", "tidy-gbbo-bakes.csv"))
```

```{r make-and-write-untidy-bakes, echo = FALSE}
untidy_bakes <- bakes_tidy  %>% 
  #spread(cake, bakes, fill = 0)
  split(.$series) %>%
  map(~ spread(.x, cake, bakes, fill = 0))
## leaves files behind for lesson on how to tidy
walk2(untidy_bakes,
      file.path("data", paste0("series", gsub(" ", "_", names(untidy_bakes)), ".csv")),
      ~ write_csv(.x, .y))
## remove series name
untidy_bakes <- untidy_bakes %>% 
  map(~select(.x, -series))
```

```{r make-and-write-untidy-gender, include = FALSE, eval = FALSE}
## leaves files behind for exercises re: how to tidy
untidy_gender <- lotr_tidy %>% 
  split(.$Gender) %>% 
  map(~ spread(.x, key = Race, value = Words)) %>% 
  map(~ select(.x, Gender, everything()))
walk2(untidy_gender, file.path("data", paste0(names(untidy_gender), ".csv")),
      ~ write_csv(.x, .y))
```

<blockquote class="twitter-tweet" lang="en"><p>If I had one thing to tell biologists learning bioinformatics, it would be &quot;write code for humans, write data for computers&quot;.</p>&mdash; Vince Buffalo (@vsbuffalo) <a href="https://twitter.com/vsbuffalo/statuses/358699162679787521">July 20, 2013</a></blockquote>

An important aspect of "writing data for computers" is to make your data __tidy__. Key features of __tidy__ data:

  * Each column is a variable
  * Each row is an observation

If you are struggling to make a figure, for example, stop and think hard about whether your data is __tidy__. Untidiness is a common, often overlooked cause of agony in data analysis and visualization.

## GBBO example {.tabset}

We will give you a concrete example of some untidy data from ["The Great British Bake Off"](https://github.com/apreshill/bakeoff).

### Series 1

```{r echo = FALSE}
untidy_bakes[[1]] %>%
  knitr::kable(caption = "Series 1")
```

### Series 2

```{r echo = FALSE}
untidy_bakes[[2]] %>%
  knitr::kable(caption = "Series 2")
```

### Series 3

```{r echo = FALSE}
untidy_bakes[[3]] %>%
  knitr::kable(caption = "Series 3")
```



We have one table per series. In each table, we have the total number of bakes, by challenge and type (cake versus pie/tart).

You could imagine finding these separate tables as separate worksheets in an Excel workbook. Or hanging out in some cells on the side of a worksheet that contains the underlying data raw data. Or as tables on a webpage or in a Word document.

This data has been formatted for consumption by *human eyeballs* (paraphrasing Murrell; see Resources). The format makes it easy for a *human* to look up the number of showstopper cakes baked in Series 2. But this format actually makes it pretty hard for a *computer* to pull out such counts and, more importantly, to compute on them or graph them.

## Exercises

Look at the tables above and answer these questions:

  * What is the total number of cakes baked in signature challenges?
  * Do pies and tarts dominate cakes any series? Does the dominant type of bake differ across the series?
  
How well does your approach scale if there were many more series or if I provided you with updated data that includes all possible bakes (custards, buns, etc.)?

## Tidy Bake Off data

Here's how the same data looks in tidy form:

```{r echo = FALSE}
datatable(bakes_tidy)
```

Notice that tidy data is generally taller and narrower. It doesn't fit nicely on the page. Certain elements get repeated alot, e.g. `showstopper`. For these reasons, we often instinctively resist __tidy__ data as inefficient or ugly. But, unless and until you're making the final product for a textual presentation of data, ignore your yearning to see the data in a compact form.

## Benefits of tidy data

With the data in tidy form, it's natural to *get a computer* to do further summarization or to make a figure. This assumes you're using language that is "data-aware", which R certainly is. Let's answer the questions posed above.

#### What's the total number of cakes baked in signature challenges?

```{r}
bakes_tidy %>% 
 count(challenge, cake, wt = bakes, sort = TRUE)
## outside the tidyverse:
#aggregate(Words ~ Gender, data = lotr_tidy, FUN = sum)
```

Now it takes a small bit of code to compute the total number of cakes for each challenge across all series. The total number of cakes baked in signature challenges is `r bakes_tidy %>% count(challenge, cake, wt = bakes) %>% filter(challenge == "signature", cake == "cake") %>% pull()`. It was important here to have all bake counts in a single variable, within a data frame that also included variables for challenge and type of bake.

####  Do pies and tarts dominate any series? Does the dominant type of bake differ across the series?

First, we sum across challenges, to obtain bake counts for the different series across episodes/challenges.

```{r}
(bakes_by_series <- bakes_tidy %>% 
   count(series, cake, wt = bakes))
## outside the tidyverse:
#(by_race_film <- aggregate(Words ~ Race * Film, data = lotr_tidy, FUN = sum))
```

We can stare hard at those numbers to answer the question. But even nicer is to depict the bake counts we just computed in a barchart. 

```{r barchart-bakes}
ggplot(bakes_by_series, aes(x = series, y = n, fill = cake)) +
  geom_col(position = "dodge") +
  coord_flip() + 
  guides(fill = guide_legend(reverse = TRUE))
```

Or we can make a line chart...
```{r}
ggplot(bakes_by_series, aes(x = series, y = n, 
                            color = cake,
                            group = cake)) +
  geom_point() +
  geom_line() +
  expand_limits(y = 0)
```


So cakes are king, at least relative to pies/tarts across all series. Pies/tarts saw a spike in popularity around series 3. Cakes really surged in the last series, series 8.

One thing missing from this data is information about total number of participants/bakes across each series, so that we can calculate proportions. 

Again, it was important to have all the data in a single data frame, all bake counts in a single variable, and associated variables for challenge and type of bake.

## Take home message

Having the data in __tidy__ form was a key enabler for our data aggregations and visualization.

Tidy data is integral to efficient data analysis and visualization.

If you're skeptical about any of the above claims, it would be interesting to get the requested word counts, the barchart, or the insight gained from the chart *without* tidying or plotting the data. And imagine redoing all of that on the full dataset, which includes 3 more Races, e.g. Dwarves.

### Where to next?

In [the next lesson](02-gather.md), we'll show how to tidy this data.

Our summing over gender to get word counts for combinations of film and race is an example of __data aggregation__. It's a frequent companion task with tidying and reshaping. Learn more at:

  * Simple aggregation with the tidyverse: `dplyr::count()` and `dplyr::group_by()` + `dplyr::summarize()`, [STAT 545 coverage](http://stat545.com/block010_dplyr-end-single-table.html#group_by-is-a-mighty-weapon), [Data transformation](http://r4ds.had.co.nz/transform.html) chapter in R for Data Science.
  * General aggregation with the tidyverse: [STAT 545 coverage](http://stat545.com/block024_group-nest-split-map.html) of general Split-Apply-Combine via nested data frames.
  * Simple aggregation with base R: `aggregate()`.
  * General aggregation with base R: `tapply()`, `split()`, `by()`, etc.

These figures were made with `ggplot2`, a popular package that implements the Grammar of Graphics in R.

### Resources

  * [Tidy data](http://r4ds.had.co.nz/tidy-data.html) chapter in R for Data Science, by Garrett Grolemund and Hadley Wickham
    - [tidyr](https://github.com/hadley/tidyr) R package
    - The tidyverse meta-package, within which `tidyr` lives: [tidyverse](https://github.com/hadley/tidyverse).
  * [Bad Data Handbook](http://shop.oreilly.com/product/0636920024422.do) by By Q. Ethan McCallum, published by O'Reilly.
    - Chapter 3: Data Intended for Human Consumption, Not Machine Consumption by Paul Murrell.
  * Nine simple ways to make it easier to (re)use your data by EP White, E Baldridge, ZT Brym, KJ Locey, DJ McGlinn, SR Supp. *Ideas in Ecology and Evolution* 6(2): 1â€“10, 2013. doi:10.4033/iee.2013.6b.6.f <http://library.queensu.ca/ojs/index.php/IEE/article/view/4608>
    - See the section "Use standard table formats"
  * Tidy data by Hadley Wickham. Journal of Statistical Software. Vol. 59, Issue 10, Sep 2014. <http://www.jstatsoft.org/v59/i10>
