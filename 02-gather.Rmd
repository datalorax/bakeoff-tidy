---
title: "Gather to Tidy Data"
author: "Alison Hill & Daniel Anderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
---

This is a lesson on tidying data, remixed from [Jenny Bryan's similar lesson using "Lord of the Rings" data](https://github.com/jennybc/lotr-tidy). Most text + code is Jenny's, basically we plopped a new dataset in there `r emo::ji("wink")`

---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE, collapse = TRUE, comment = "#>", warning = FALSE, message = FALSE)
library(DT)
ggplot2::theme_set(ggplot2::theme_minimal())
```

An important aspect of "writing data for computers" is to make your data __tidy__. Key features of __tidy__ data:

  * Each column is a variable
  * Each row is an observation

But unfortunately, __untidy__ data abounds. In fact, we often inflict it on ourselves, because untidy formats are more attractive for data entry or examination. So how do you make __untidy__ data __tidy__?

## Import 

We now import the untidy data from the eight series that was presented in [the
intro](01-intro.html).

I assume that data can be found as eight plain text, delimited files, one for each film, each with the filename `series*.csv`. How to liberate data from spreadsheets or tables in word processing documents is beyond the scope of this tutorial. 

The files live [in this repo](https://github.com/apreshill/bakeoff-tidy), which you could clone as a new RStudio Project. We'll use a neat trick to read in all 8 csv files at once:

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">‚òùÔ∏è My first <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> tip: use purrr::map_df() to read all .csv files in a üìÇ and stick them in a single data frame:<br><br>f &lt;- list.files(<br>  &quot;my_folder&quot;,<br>   pattern = &quot;*.csv&quot;,<br>   full.names = TRUE)<br><br>d &lt;- purrr::map_df(f, readr::read_csv, .id = &quot;id&quot;) <a href="https://t.co/JWxI5ecr0k">pic.twitter.com/JWxI5ecr0k</a></p>&mdash; We are R-Ladies (@WeAreRLadies) <a href="https://twitter.com/WeAreRLadies/status/1034817323922804737?ref_src=twsrc%5Etfw">August 29, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


You do not need to know how the below code works- please treat it like a magic black box for now! You'll learn more about these packages and functions in the third course of this series.


```{r results='hide'}
library(tidyverse)
library(here)
bakes_untidy <- fs::dir_ls(path = here("data"), 
                          regexp = "series\\d.csv") %>% 
  purrr::map_df(readr::read_csv)
```



We now have one data frame with bake counts for all 8 series, across both the signature and showstopper challenges.

```{r}
bakes_untidy
glimpse(bakes_untidy)
```

Assembling one large data object from lots of little ones is a common data preparation task. When the pieces are as similar as they are here, it's nice to assemble them into one object right away. In other scenarios, you may need to do some remedial work on the pieces before they can be fitted together nicely.

A good guiding principle is to glue the pieces together as early as possible, because it's easier and more efficient to tidy a single object than 20 or 1000.

## Tidy 

We are still violating one of the fundamental principles of __tidy data__. "Bake count" is a fundamental variable in our dataset and it's currently spread out over two variables, `cake` and `pie_tart`. Conceptually, we need to gather up the bake counts into a single variable and create a new variable, `n_bakes`, to track whether each count refers to cakes or pies/tarts. We use the `gather()` function from the tidyr package to do this.

```{r}
bakes_tidy <- bakes_untidy %>% 
  gather(key = 'type_bake', value = 'n_bakes', cake, pie_tart)
bakes_tidy
```

Tidy data ... mission accomplished!

To explain our call to `gather()` above, let's read it from right to left: we took the variables `cake` and `pie_tart` and gathered their *values* into a single new variable `n_bakes`. This forced the creation of a companion variable `type_bake`, a *key*, which tells whether a specific value of `n_bakes` came from `cake` or `pie_tart`. All other variables, such as `challenge`, remain unchanged and are simply replicated as needed. The documentation for `gather()` gives more examples and documents additional arguments.

## Export

Now we write this multi-series, tidy dataset to file for use in various downstream scripts for further analysis and visualization. This would make an excellent file to share on the web with others, providing a tool-agnostic, ready-to-analyze entry point for anyone wishing to play with this data.

```{r}
write_csv(bakes_tidy, path = here("data", "bakes_tidy.csv")) 
```

You can inspect this delimited file here: [bakes_tidy.csv](data/bakes_tidy.csv).

## Exercises

Choose one of three tidying adventures:

### `Bachelorette`

Follow along with these code prompts:

* Use the following code to read in data used from several stories from [538](https://github.com/fivethirtyeight/data/tree/master/bachelorette) (Note: you'll get a bunch of parsing errors and that is OK to ignore):

```{r}
# import bachelor data
bach <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/bachelorette/bachelorette.csv",
                         col_types = cols(SEASON = col_integer()))

```

* Create a dataset that looks like this:

```{r echo = FALSE}
# tidy bachelor data
b_tidy <- bach %>% 
  filter(!SEASON == "SEASON") %>% 
  select(SHOW, SEASON, CONTESTANT, starts_with("ELIMINATION")) %>% 
  gather(key = "week", value = "eliminated", starts_with("ELIMINATION"), na.rm = TRUE) %>% 
  mutate(week = str_replace(week, "-", "_"),
         week = parse_number(week))
b_tidy

```

Use this code template if you want some help getting there:

```{r eval = FALSE}
# template code to tidy bachelor data
b_tidy <- bach %>% 
  filter(!SEASON == "SEASON") %>% 
  select(SHOW, SEASON, CONTESTANT, starts_with("ELIMINATION")) %>% 
  gather(key = <what is the key var you want?>, 
         value = <what is the value var you want?>, 
         <select which vars you want to gather?>, 
         na.rm = TRUE) %>% 
  mutate(week = str_replace(week, "-", "_"),
         week = parse_number(week))
b_tidy

```



* Use the tidy dataset to answer the following questions:

1. How many contestants were eliminated in week 3? What about for the Bachelor vs. the Bachelorette?
1. Make a bar chart to show the number of roses given to contestants ("R1" is first impression rose, "R" is a normal rose), facetted by show.

Some sample output you might want to aim for:

```{r, echo = FALSE}
# eliminated in week 3
b_tidy %>% 
  mutate(elim = if_else(eliminated %in% c("R", "R1", "W"), 0, 1)) %>% 
  count(week, elim) %>% 
  filter(week == 3)

# eliminated in week 3 by show
b_tidy %>% 
  mutate(elim = if_else(eliminated %in% c("R", "R1", "W"), 0, 1)) %>% 
  count(SHOW, week, elim) %>% 
  filter(week == 3)

# roses received
b_roses <- b_tidy %>% 
  filter(eliminated %in% c("R1", "R")) 
ggplot(b_roses, aes(x = SEASON)) +
  geom_bar() +
  facet_wrap(~ SHOW)

```

### PDX Bike Counts

Follow along with these code prompts:

* Use the following code to read in data used from the annual PDX Bike Count [538](https://github.com/fivethirtyeight/data/tree/master/bachelorette):

<!-- The above link is to the 538 bachelorette. I can't seem to find the original link -->

```{r}
# import bike data
untidy_bikes <- read_csv("https://raw.githubusercontent.com/apreshill/bakeoff-tidy/master/data/untidy-bike-counts.csv", 
                         skip = 1,
                         na = "-") %>% 
  janitor::clean_names() # optional but highly recommended
glimpse(untidy_bikes)

```

* Gather all the bike counts for years 2000-2017 (Hint: you may need to use a `mutate` with `parse_number` after the `gather`). Your finished tibble should look like:

```{r echo = FALSE}
# gather bike counts
tidy_bikes <- untidy_bikes %>% 
  select(-prior_to_2000) %>% 
  gather(key = "year", value = "bike_count", x2017:x2000) %>% 
  mutate(year = parse_number(year))

# the tidied bike data
datatable(tidy_bikes)

```

* Count bikes by sector.

```{r echo = FALSE}
# count bikes by sector
tidy_bikes %>% 
  count(sector, wt = bike_count)

```


* Make a plot to show the number of bikes counted across the years, facetting by sector. Has there been a steady increasing trend in bikes counted across all sectors? Which sectors have seen the most bikes counted recently?

```{r echo = FALSE}
# plot bike counts by year and sector
ggplot(tidy_bikes, aes(x = year, y = bike_count)) +
  geom_col() +
  facet_wrap(~sector) 

```


### 538 Flying Etiquette Survey

Follow along with these code prompts:

* Use the following code to read in data used from [538](https://github.com/fivethirtyeight/data/tree/master/flying-etiquette-survey):

```{r}
# import flying etiquette data
untidy_fly <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/flying-etiquette-survey/flying-etiquette.csv") %>% 
  mutate_if(is.character, as.factor)
```


* Select the participant ID and any question columns which include the word "rude", then `gather` all the "rude" question columns.

```{r echo = FALSE}
# select then gather questions about rudeness
tidy_rude <- untidy_fly %>% 
  select(RespondentID, contains("rude")) %>%
  gather(key = "question_asked", value = "answer", -RespondentID) %>% 
  mutate(rude_answer = if_else(str_detect(answer, "Yes"), 1, 0))

```

* Answer some questions: how many respondents are there? how many respondents didn't answer any of the 9 questions? Try filtering out respondents who had missing answers for all 9 questions here.

```{r echo = FALSE}
# number of respondents
n_distinct(tidy_rude$RespondentID)

# some who didn't answer any of these questions
tidy_rude %>% 
  count(RespondentID, rude_answer) %>% 
  filter(is.na(rude_answer)) %>% 
  count(n)

# filter out non-respondents
tidy_rude <- tidy_rude %>% 
  group_by(RespondentID) %>% 
  filter(sum(is.na(rude_answer)) < 9)

# now less respondents in sample
n_distinct(tidy_rude$RespondentID)
```


* Summarize the data: `group_by` question, then calculate the mean of your new `rude_answer` column to get the proportions of respondents who endorsed "yes it is rude" for each question.

```{r echo = FALSE}
# summarize the rude answers
(rude_summarized <- tidy_rude %>% 
  group_by(question_asked) %>% 
  summarize(rude_prop = mean(rude_answer, na.rm = TRUE)))
```


* Make this kind of bar chart with the summarized version of your tidy data- it doesn't need to be perfect! See below for our recreation:

![](https://fivethirtyeight.com/wp-content/uploads/2014/09/hickey-datalab-flying.png)

For more tweaking, you can use this code to redo your labels:

```{r echo = TRUE}
abb_question <- tribble(
  ~label,
  "be chatty with seatmate",
  "knowingly bring unruly children",
  "bring a baby on a plane",
  "ask to switch seats for friends",
  "wake someone up to go to the bathroom",
  "ask to switch seats for family",
  "move to an unsold seat",
  "recline your seat",
  "wake someone up to go for a walk"
)
rude_summarized <- tidy_rude %>% 
  group_by(question_asked) %>% 
  summarize(rude_prop = mean(rude_answer, na.rm = TRUE)) %>% 
  bind_cols(abb_question)
```

```{r echo = FALSE, fig.height = 5, fig.width = 8}
# recreate 538 bar chart
ggplot(rude_summarized, aes(x = fct_reorder(label, rude_prop), y = rude_prop)) +
  geom_col(fill = "dodgerblue", alpha = .5) +
  coord_flip(ylim = c(0, 1)) +
  labs(x = NULL, y = NULL) +
  geom_text(aes(label = scales::percent(rude_prop)), hjust = -.25) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```





## Take home message

It is untidy to have data parcelled out across different files or data frames. 

It is untidy to have a conceptual variable, e.g. "word count", "bake count", "bike count", "rose count", spread across multiple variables, such as bike counts for each year. We used the `gather()` function from the tidyr package to stack up all these counts into a single variable, create a new variable to convey the categorical or factor variable that was previously "hidden" to us in the column names, and do the replication needed for the other variables.

Many data analytic projects will benefit from a script that marshals data from different files, tidies the data, and writes a clean result to file for further analysis.

Watch out for how __untidy__ data seduces you into working with it more than you should:

  * Data optimized for consumption by human eyeballs *is* attractive, so it's hard to remember it's suboptimal for computation. How can something that looks so pretty be so wrong?
  * Tidy data often has lots of repetition, which triggers hand-wringing about efficiency and aesthetics. Until you can document a performance problem, keep calm and tidy on.
  * Tidying operations are unfamiliar to many of us and we avoid them, subconsciously preferring to faff around with other workarounds that are more familiar.

### Where to next?

In the next lesson [03-spread](03-spread.html) I show you how to untidy data, using `spread()` from the tidyr package. This might be useful at the end of an analysis, for preparing figures or tables.

### Resources

  * [Tidy data](http://r4ds.had.co.nz/tidy-data.html) chapter in R for Data Science, by Garrett Grolemund and Hadley Wickham
    - [tidyr](https://github.com/hadley/tidyr) R package
    - The tidyverse meta-package, within which `tidyr` lives: [tidyverse](https://github.com/hadley/tidyverse).
  * [Bad Data Handbook](http://shop.oreilly.com/product/0636920024422.do) by By Q. Ethan McCallum, published by O'Reilly.
    - Chapter 3: Data Intended for Human Consumption, Not Machine Consumption by Paul Murrell.
  * Nine simple ways to make it easier to (re)use your data by EP White, E Baldridge, ZT Brym, KJ Locey, DJ McGlinn, SR Supp. *Ideas in Ecology and Evolution* 6(2): 1‚Äì10, 2013. doi: 10.4033/iee.2013.6b.6.f <https://ojs.library.queensu.ca/index.php/IEE/article/view/4608>
    - See the section "Use standard table formats"
  * Tidy data by Hadley Wickham. Journal of Statistical Software. Vol. 59, Issue 10, Sep 2014. <http://www.jstatsoft.org/v59/i10>
  
### Code Appendix

```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```


